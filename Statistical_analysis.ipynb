{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Installing required libraries for statistical analysis\n",
    "!pip install scipy # For performing statistical operations\n",
    "!pip install pandas # Stores data from analysis into tables\n",
    "!pip install numpy # For numerical operations and array manipulation\n",
    "!pip install statsmodels # For False Discovery rate (FDR) correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f164f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - Importing packages required for statistical analysis\n",
    "import os # For interacting with the operating system\n",
    "import numpy as np # For numerical operations and array manipulation\n",
    "import pandas as pd # Stores data from analysis into tables\n",
    "from scipy.stats import mannwhitneyu # To apply the Mann-Whitney U test\n",
    "from statsmodels.stats.multitest import multipletests # For False Discovery rate (FDR) correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c195769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Statistical analysis code\n",
    "# -------- ROUT-like outlier removal --------\n",
    "def rout_outlier_removal(data, Q=1):\n",
    "    \"\"\"\n",
    "    Approximate ROUT outlier filtering using robust Z (median/MAD).\n",
    "    Q controls stringency: 0.1 ~ lenient, 1 ~ default, 5 ~ stricter.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(data, dtype=float)\n",
    "    arr = arr[np.isfinite(arr)]  # drop NaN/Inf\n",
    "    if arr.size < 3:\n",
    "        return arr\n",
    "    median = np.median(arr)\n",
    "    mad = np.median(np.abs(arr - median))\n",
    "    if mad == 0:\n",
    "        return arr\n",
    "    robust_z = 0.6745 * (arr - median) / mad\n",
    "    cutoff = {0.1: 4.5, 1: 3.5, 5: 2.8}.get(int(Q), 3.5)\n",
    "    kept = arr[np.abs(robust_z) <= cutoff]\n",
    "    return kept if kept.size > 0 else arr  # safeguard\n",
    "\n",
    "def _star_code(p):\n",
    "    if p < 1e-4: return \"****\"\n",
    "    if p < 1e-3: return \"***\"\n",
    "    if p < 1e-2: return \"**\"\n",
    "    if p < 5e-2: return \"*\"\n",
    "    return \"ns\"\n",
    "\n",
    "# -------- Main statistical analysis --------\n",
    "def statistical_analysis(input_csv, output_dir, Q=1):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Ensure group column\n",
    "    if \"Group\" in df.columns:\n",
    "        group_col = \"Group\"\n",
    "    elif \"group\" in df.columns:\n",
    "        group_col = \"group\"\n",
    "    else:\n",
    "        raise ValueError(\"The input CSV must contain a 'Group' or 'group' column.\")\n",
    "\n",
    "    # Validate exactly 2 groups and map deterministically\n",
    "    labels = df[group_col].dropna().unique()\n",
    "    if len(labels) != 2:\n",
    "        raise ValueError(f\"Expected exactly 2 groups in '{group_col}', found: {labels}\")\n",
    "\n",
    "    group_map = {labels[0]: 0, labels[1]: 1}\n",
    "    df[\"_group_code\"] = df[group_col].map(group_map)\n",
    "    g0_label, g1_label = labels[0], labels[1]\n",
    "\n",
    "    # Numeric columns (exclude code)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    feature_cols = [c for c in num_cols if c != \"_group_code\"]\n",
    "    if not feature_cols:\n",
    "        raise ValueError(\"No numeric feature columns found to analyze.\")\n",
    "\n",
    "    y = df[\"_group_code\"].values\n",
    "    rows = []\n",
    "\n",
    "    # Mann - Whitney per feature (with ROUT filtering)\n",
    "    for feat in feature_cols:\n",
    "        x0 = df.loc[y == 0, feat].values\n",
    "        x1 = df.loc[y == 1, feat].values\n",
    "        x0_f = rout_outlier_removal(x0, Q=Q)\n",
    "        x1_f = rout_outlier_removal(x1, Q=Q)\n",
    "        if x0_f.size == 0 or x1_f.size == 0:\n",
    "            continue\n",
    "\n",
    "        stat, p = mannwhitneyu(x0_f, x1_f, alternative=\"two-sided\")\n",
    "        mean0, mean1 = float(np.mean(x0_f)), float(np.mean(x1_f))\n",
    "        # Direction by medians (more in line with MWU); change to means if you prefer\n",
    "        med0, med1 = float(np.median(x0_f)), float(np.median(x1_f))\n",
    "        direction = f\"↑ {g1_label}\" if med1 > med0 else f\"↓ {g1_label}\"\n",
    "        sig_raw = _star_code(p)\n",
    "\n",
    "        rows.append([\n",
    "            feat, stat, p,\n",
    "            mean0, mean1,\n",
    "            med0, med1,\n",
    "            direction, sig_raw\n",
    "        ])\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No valid features survived ROUT filtering or insufficient data for tests.\")\n",
    "        return\n",
    "\n",
    "    df_results = pd.DataFrame(rows, columns=[\n",
    "        \"Feature\", \"U_stat\", \"raw_p_value\",\n",
    "        f\"Mean_{g0_label}\", f\"Mean_{g1_label}\",\n",
    "        f\"Median_{g0_label}\", f\"Median_{g1_label}\",\n",
    "        \"Direction\", \"Significance_raw\"\n",
    "    ])\n",
    "\n",
    "    # ---------------- RAW CSV: ONLY MWU columns ----------------\n",
    "    df_raw = df_results.sort_values(\"raw_p_value\", na_position=\"last\").reset_index(drop=True)\n",
    "    raw_cols = [\n",
    "        \"Feature\", \"U_stat\", \"raw_p_value\",\n",
    "        f\"Mean_{g0_label}\", f\"Mean_{g1_label}\",\n",
    "        f\"Median_{g0_label}\", f\"Median_{g1_label}\",\n",
    "        \"Direction\", \"Significance_raw\"\n",
    "    ]\n",
    "    raw_path = os.path.join(output_dir, \"mann_whitney_raw.csv\")\n",
    "    df_raw[raw_cols].to_csv(raw_path, index=False)\n",
    "\n",
    "    # ---------------- FDR CSV: MWU + FDR columns ----------------\n",
    "    df_fdr = df_raw.copy()\n",
    "    df_fdr[\"adj_p_value\"] = np.nan\n",
    "    df_fdr[\"Significance_FDR\"] = \"ns\"\n",
    "\n",
    "    valid_mask = df_fdr[\"raw_p_value\"].notna().values\n",
    "    if valid_mask.any():\n",
    "        _, pvals_corrected, _, _ = multipletests(\n",
    "            df_fdr.loc[valid_mask, \"raw_p_value\"].values,\n",
    "            method=\"fdr_bh\"\n",
    "        )\n",
    "        df_fdr.loc[valid_mask, \"adj_p_value\"] = pvals_corrected\n",
    "        df_fdr.loc[valid_mask, \"Significance_FDR\"] = [\n",
    "            _star_code(pv) for pv in df_fdr.loc[valid_mask, \"adj_p_value\"].values\n",
    "        ]\n",
    "\n",
    "    df_fdr = df_fdr.sort_values(\"adj_p_value\", na_position=\"last\").reset_index(drop=True)\n",
    "    fdr_path = os.path.join(output_dir, \"mann_whitney_FDR.csv\")\n",
    "    df_fdr.to_csv(fdr_path, index=False)\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    print(\"  • RAW (MWU only):\", raw_path)\n",
    "    print(\"  • FDR (MWU + FDR):\", fdr_path)\n",
    "    print(\"\\nTop (FDR-sorted):\")\n",
    "    print(df_fdr.head(15).to_string(index=False))\n",
    "\n",
    "# -------- RUN --------\n",
    "if __name__ == \"__main__\":\n",
    "    # You can switch between your MFTA or Radiomics CSVs here:\n",
    "    input_csv = \"/Users/MFTA_results.csv\" # <-- remove # if you want to analyse MFTA\n",
    "    # input_csv = \"/Users/Radiomics_results.csv\" # <-- remove # if you want to analyse Radiomics\n",
    "    \n",
    "    output_dir = \"/Users/Output\" # Change to your output pathanme\n",
    "    statistical_analysis(input_csv, output_dir, Q=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
